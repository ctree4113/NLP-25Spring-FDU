@article{huang2025hira,
  title={Hi{RA}: High-Rank Adaptation for Parameter-Efficient Fine-Tuning},
  author={Huang, Wenqi and Wang, Yinpeng and Dong, Li and Wei, Furu and Bao, Hangbo},
  journal={arXiv preprint arXiv:2402.12198},
  year={2024}
}

@article{wang2024kasa,
  title={{KaSA}: Knowledge-aware Singular value Adaptation for Parameter-Efficient Fine-tuning},
  author={Wang, Minghao and Shi, Yao and Hou, Xuming and Li, Lei and Zheng, Hai-Tao and Wang, Wei},
  journal={arXiv preprint arXiv:2403.09054},
  year={2024}
}

@article{llm-adapters,
  title={Parameter-Efficient Fine-Tuning without Introducing New Latency in a Single Forward Pass},
  author={Zhang, Yuanxin and Huang, Jiacen and Dai, Qiying and Zhang, Zhilin},
  journal={arXiv preprint arXiv:2305.17593},
  year={2023}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{hu2021lora,
  title={Lo{RA}: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{kopiczko2023vera,
  title={Ve{RA}: Vector-based Random Matrix Adaptation},
  author={Kopiczko, Piotr and Wossnig, Leonard and Jaunet, Jonas},
  journal={arXiv preprint arXiv:2310.11454},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{yang2024qwen2,
  title={Qwen2: Advancing Reasoning with an Evolving Code Synthesis Framework},
  author={Yang, Jian and Wang, Kaitao and Zhang, Tianyu and Zan, Wentao and Hu, Gang and Zhu, Peiyu and Zhao, Peng and Li, Qian and Mao, Rui and Chang, Renjie and others},
  journal={arXiv preprint arXiv:2407.02151},
  year={2024}
}